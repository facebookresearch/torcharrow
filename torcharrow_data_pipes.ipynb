{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd056f626f2aa31d1996176a2034a75bfff22e4b2d79ede5b92d2ea330b3279997c",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Torcharrow: Data Pipes\n",
    "\n",
    "Typical torcharrow programs often wrangle data in an imperative fashion. This enables step-wise program development, thereby easing debugging and experimentation. However imperative dataframe programs require introducing lots of intermediate results. \n",
    "\n",
    "On the other hand, a purely functional version can often be constructed by just composing one dataframe operator after another. In the Pandas community this style is also known as data pipes.\n",
    "\n",
    "Luckily both styles are available to anyone using the torcharrow library. To see the differences let's analyze the US Department of Transportation's data for flight data. \\[Remark: To make this workbook self-contained we don't open a DB connection or read a CSV file but just use random data. The variable `flights` represents our database.\\]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    dep_delay    arr_delay\n",
       "-------  -----------  -----------\n",
       "      0            6            5\n",
       "      1            1            7\n",
       "      2            4            7\n",
       "      3            8            6\n",
       "      4            1            7\n",
       "dtype: Struct([Field('dep_delay', int64), Field('arr_delay', int64)]), count: 5, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import random\n",
    "import torcharrow as ta\n",
    "\n",
    "\n",
    "dep_sample = [random.randrange(1, 10, 1) for i in range(70)]\n",
    "arr_sample = [random.randrange(1, 10, 1) for i in range(70)]\n",
    "N = 5\n",
    "\n",
    "flights = ta.DataFrame({\n",
    "    'dep_delay':ta.Column(dep_sample), \n",
    "    'arr_delay':ta.Column(arr_sample)})\n",
    "flights.head(5)"
   ]
  },
  {
   "source": [
    "\n",
    "## Imperative code \n",
    "Here is an example program that finds the flights and their dep(arture)_delay by the minute. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    dep_delay    arrival_delay    numflights\n",
       "-------  -----------  ---------------  ------------\n",
       "      0            9          5.57143             7\n",
       "      1            8          5.55556             9\n",
       "      2            7          4.33333             9\n",
       "      3            6          4.75                8\n",
       "      4            4          5.76923            13\n",
       "dtype: Struct([Field('dep_delay', int64), Field('arrival_delay', float64), Field('numflights', int64)]), count: 5, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\n",
    "\n",
    "grouped_flights = flights.groupby(['dep_delay'])\n",
    "\n",
    "tmp = ta.DataFrame()\n",
    "tmp['dep_delay'] = grouped_flights['dep_delay']\n",
    "tmp['arrival_delay'] = grouped_flights[\"arr_delay\"].mean()\n",
    "tmp['numflights'] =  grouped_flights[\"arr_delay\"].count()\n",
    "\n",
    "filtered = tmp[tmp['numflights']>N]\n",
    "sorted = filtered.sort(by=['dep_delay'], ascending=False)\n",
    "sorted.head(5)"
   ]
  },
  {
   "source": [
    "## Functional code aka data pipes\n",
    "\n",
    "The corresponding data pipe looks like this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from torcharrow import me\n",
    "\n",
    "(flights\n",
    ".groupby(['dep_delay'])\n",
    ".select(\n",
    "    arrival_delay = me['arr_delay'].mean(),\n",
    "    numflights = me['arr_delay'].count())\n",
    ".where(me['numflights']>N)\n",
    ".sort(by=['dep_delay'], ascending=False)\n",
    ".head(5)\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    dep_delay    arrival_delay    numflights\n",
       "-------  -----------  ---------------  ------------\n",
       "      0            9          5.57143             7\n",
       "      1            8          5.55556             9\n",
       "      2            7          4.33333             9\n",
       "      3            6          4.75                8\n",
       "      4            4          5.76923            13\n",
       "dtype: Struct([Field('dep_delay', int64), Field('arrival_delay', float64), Field('numflights', int64)]), count: 5, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "source": [
    "Everything is composed in a fluent style. But due to the missing temporaries, expressions like `tmp['numflights']>300` had to be rewritten as `me['numflights']>300`. But where does `me` come from?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Expression Trees and `me`\n",
    "\n",
    "In torcharrow any reference to the global `me`, which is typed as a dataframe, constructs an expression tree. That tree is only evaluated when the hosting dataframe is being executed, in which case `me` is bound to `self`.\n",
    "\n",
    "The signature of `where` makes the distinction between passing a function and passing an expression tree explicit. We have: \n",
    "\n",
    "```\n",
    "    def Dataframe.where(self, condition:Union[Callable, Expression): ...\n",
    "```\n",
    "\n",
    "The call of `where` with the expression tree\n",
    "\n",
    "```\n",
    "   df.where(me['numflights']>300)\n",
    "```\n",
    "\n",
    "is semantically exactly the same as passing a lambda where at call time `me` is bound to `self`.\n",
    "\n",
    "```\n",
    "    df.where(lambda me: me['numflights']>300)\n",
    "```\n",
    "\n",
    "We see that the expression tree form is not only shorter, but it also makes at runtime every attribute access and call explicit and thus easily analyzable. This stands in contrast to the use of the lambda, which code is not inspectable at runtime."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Torcharrow, SQL, UPM, back and forth\n",
    "\n",
    "It is easy to see that the imperative and functional versions are the same. It should also be obvious that torcharrow programs that only use the column and dataframe API actually correspond to SQL, too. The program above could, for example, be written as:\n",
    "\n",
    "```\n",
    "    SELECT \n",
    "        dep_delay, \n",
    "        MEAN(arr_delay) AS arrival_delay, \n",
    "        COUNT(arr_delay) AS numflights, \n",
    "    FROM flight\n",
    "    GROUP BY dep_delay\n",
    "    WHERE numflights > 300\n",
    "    SORT BY dep_delay\n",
    "    LIMIT 10\n",
    "```\n",
    "\n",
    "Torcharrow will eventually support all relational operators, e.g where, select, join, group-by, sort, union, except, limit, etc.\n",
    "\n",
    "Used in this way torcharrow is similar to UPM. However there are several big differences:\n",
    " * torcharrow is a lightweight API with a single box runtime and dynamically checked types.\n",
    " * UPM is a precompiler with strong static typing targeting various platforms: Presto, HQL and XStream.\n",
    " * In torcharrow all embedded expressions have to be authored in Python proper.\n",
    " * In UPM these expressions are strings and have to follow Presto or HQL syntax.\n",
    "\n",
    "The good news is that we can translate one into the other. In fact, we plan to translate torcharrow into the intermediate language for UPM so that torcharrow benefits from UPM's deep analysis and optimization stack. And vice versa one could consider translating UPM into torcharrow to execute it locally."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pipes: Compositional SQL \n",
    "The big benefit of Python over SQL is that we can easily build procedural abstractions. Suppose we define:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_control(df):\n",
    "    return df.where(me['numflights']>N)"
   ]
  },
  {
   "source": [
    "We can use `quality_control` in above data pipe. However `quality_control` is not defined on dataframe and thus doesn't compose in a fluent style. Luckily we can use Panda's `pipe` operator:\n",
    "\n",
    "```\n",
    "    def Dataframe.pipe(self, func, *args, **kwargs):\n",
    "```\n",
    "        \n",
    "When `pipe` executes it simply calls the passed func(tion) like this `func(self, *args, **kwargs)`. \n",
    "\n",
    "Applying the pipe operator, we can still write our pipeline as:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "(flights\n",
    ".groupby(['dep_delay'])\n",
    ".select(\n",
    "    arrival_delay = me['arr_delay'].mean(),\n",
    "    numflights = me['arr_delay'].count())\n",
    ".pipe(quality_control)\n",
    ".sort(by=['dep_delay'], ascending=False)\n",
    ".head(5)\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    dep_delay    arrival_delay    numflights\n",
       "-------  -----------  ---------------  ------------\n",
       "      0            9          5.57143             7\n",
       "      1            8          5.55556             9\n",
       "      2            7          4.33333             9\n",
       "      3            6          4.75                8\n",
       "      4            4          5.76923            13\n",
       "dtype: Struct([Field('dep_delay', int64), Field('arrival_delay', float64), Field('numflights', int64)]), count: 5, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "source": [
    "## Summary\n",
    "\n",
    "Torcharrow allows to author dataframes in an imperative and functional way. Both are semantically the same! And \n",
    "by using the `pipe` operator user-defined-functions can be integrated into the fluent style, too.  \n",
    "\n",
    "By leveraging `me`, one can refer to the current dataframe inside of expressions. This allows to author lambda expressions succinctly  and makes them even analyzable. \n",
    "\n",
    "By combining expressions trees with [tracing](./torcharrow_state.ipynb), we can translate most torcharrow program to UPM and thus to SQL.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
