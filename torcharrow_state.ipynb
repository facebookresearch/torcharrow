{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd056f626f2aa31d1996176a2034a75bfff22e4b2d79ede5b92d2ea330b3279997c",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Torcharrow: State handling -- Scopes, Multi-targeting and Tracing\n",
    "\n",
    "\n",
    "Torcharrow has **no global mutable state**. But it has the concept of a scope which is threaded implicitly through a pipeline. This allows for configuration management, multi-device targeting and tracing. This short doc explain the concepts and their use.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## Scopes\n",
    " \n",
    "Each torcharrow pipeline runs within the context of a scope. A scope defines the pipelines configuration settings and thus influences location and behavior of columns, dataframes and their operations. Users can explicitly create a scope by calling various Scope constructors. The simplest one creates the default Scope...\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcharrow as T\n",
    "import torcharrow.dtypes as dt\n",
    "\n",
    "ts = T.Scope()"
   ]
  },
  {
   "source": [
    "The default scope has the following three default settings:\n",
    "\n",
    "- `device`: `std`, means that the columns and dataframes are allocated as numpy arrays (see section below on  Multi-device targeting for more details)\n",
    "- `tracing`: `False`, means that the code is currently not traced (see section below on Tracing for more details)\n",
    "- `types_to_trace`: `[]`, if tracing holds, then only these types will be traced."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Column and Dataframe Factories\n",
    "\n",
    "Columns and dataframes are created with respect to a scope. Columns and dataframes inherit the scopes' settings. Here we show that a column or dataframe inherits the device setting, which is accessible under the `device` property of the created column or dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Column c: [1, 2, 3], its device: std\nDataFrame d: [(1, 'a'), (2, 'b'), (3, 'c')], its device: std)\n"
     ]
    }
   ],
   "source": [
    "c = ts.Column([1,2,3])\n",
    "d = ts.DataFrame({'a': [1,2,3], 'b' : ['a','b','c']})\n",
    "print(f\"Column c: {list(c)}, its device: {c.device}\")\n",
    "print(f\"DataFrame d: {list(d)}, its device: {d.device})\")"
   ]
  },
  {
   "source": [
    "Most programs don't have to worry about scopes at all. They can just use public constructor `Column` and `Frame` which implicitly pick up the scope's default. So TorchArrow non-power users can be completely unaware of configs, sessions, multi-device targeting, tracing, etc.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'std'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "d = T.Column(['abc',None])\n",
    "d.device"
   ]
  },
  {
   "source": [
    "Note: We call the factory method for a `DataFrame` currently simply `Frame`, since `DataFrame` denotes the resulting class but `Frame` is not its constructor, but a factory method!. Once we make all classes Device specific we can have `DataFrame` back."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Multi-device targeting\n",
    "\n",
    "Torcharrow supports multi-device targeting - i.e., columns and dataframes can reside in different memory (which we call also device). Currently we support 3 configurations:\n",
    "\n",
    "- std, which means columns and dataframes are backed by by Numpy\n",
    "- cpu, which means columns and dataframes are backed by Velox,\n",
    "- gpu, which means columns and dataframes are backed by CuPy (i.e. GPU memory).\n",
    "\n",
    "The user controls the assignment in 3 ways:\n",
    "\n",
    "- the default assignment is done via the config's `device` parameter. The current device default is `std`. \n",
    "- the `device` parameter of the `Column` or `(Data)Frame` factory method. If `device` is None, the data is allocated at the default device; otherwise it is created at the specified device.\n",
    "- the `to` instance method call defined on the base class `IColumn`. The method moves the column/frame to the designated device. \n",
    "\n",
    "Torcharrow requires that  \n",
    "- creation of a dataframe on a particular device assumes that all its columns are created on the same device. \n",
    "- applying an operation on a column or dataframe will result in a column or dataframe on the same device.\n",
    "- if the operation requires several columns/frames as input, all of them have to be on the same device.\n",
    "\n",
    "Let's see this in practice: First we create a dataframe and we inspect the dataframe's and column's `device`...\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('test', 'test', 'test', 'test')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "e =T.Frame({'a': [1.0, None], 'b':['a','c']})\n",
    "f = e['a'] > 12\n",
    "(e.device, e['a'].device, e['b'].device, f.device ) "
   ]
  },
  {
   "source": [
    "Alternatively we could have created a column/frame on a particular device:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "g = T.Column([1.0, None], device = 'cpu')\n",
    "g.device"
   ]
  },
  {
   "source": [
    "To add `e['a']` to `f` we have to bring the columns to the same device. Let's say it is `cpu`. Then add will return a new column on `cpu`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "h = e['a'].to('cpu') + g\n",
    "h.device"
   ]
  },
  {
   "source": [
    "The system raises a TypeError if two columns to add reside on different devices."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.Column([1], device = 'cpu') \n",
    "y = T.Column([1], device = 'std')\n",
    "try:\n",
    "    z = x+y\n",
    "except TypeError as e:\n",
    "    print(f\"error: {e}\")\n"
   ]
  },
  {
   "source": [
    "## Tracing\n",
    "\n",
    "\n",
    "Torcharrow programs are executed eagerly -- that is every expression is evaluated bottom up and statements  are executed one after another. While this is fast and allows developers to debug programs easily it doesn't allow to inspect the executed code for analysis, optimization or platform re-targeting. \n",
    "\n",
    "To get the best of both worlds, fast execution, and ease of analyzability, torcharrow introduces tracing. To create a torcharrow trace, author a new setting, in which you set `tracing` to True and provide the types of classes that you want to trace. For Torcharrow the tracing defaults should always include `Scope`, `IColumn` and `GroupedDataFrame`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "types= [T.Scope, T.IColumn, T.GroupedDataFrame]\n",
    "settings = {'tracing': True, 'types_to_trace':types}"
   ]
  },
  {
   "source": [
    "\n",
    "Next we run the program unchanged. For visibility on what happens we print out the resulting dataframe, each column having particular object ids, here named `s`*i* and `c`*i*. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"self._fromdata({'a':Column([], id = c0), 'b':Column([], id = c1), 'c':Column([], id = c2), 'e':Column([], id = c4), id = c5})\""
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from torcharrow import me\n",
    "\n",
    "ts = T.Scope(settings)\n",
    "d0 = ts.DataFrame(dtype=dt.Struct([dt.Field(i, dt.int64) for i in ['a', 'b', 'c']]))\n",
    "d1 = d0.select('*', e=me['a'] + me['b'])\n",
    "str(d1)"
   ]
  },
  {
   "source": [
    "A faithful trace should have captured this execution and be able to replay with the same results.  Let's see whether that's the case:\n",
    "\n",
    "The generated `trace` is accessible via the `session` object. The trace has two components:\n",
    "-  `statements` returns a list of assignments where each\n",
    "   - right hand side is an operation of the types to trace  \n",
    "   - left hand side is named after the object id that's is created by the right hand side \n",
    "- `result` returns the name of the variable that was last assigned. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('c5',\n",
       " [\"c3 = torcharrow.scope.Scope.DataFrame(s0, dtype=Struct([Field('a', int64), Field('b', int64), Field('c', int64)]))\",\n",
       "  \"c5 = torcharrow.dataframe.DataFrame.select(c3, '*', e=torcharrow.dataframe.me.__getitem__('a').__add__(torcharrow.dataframe.me.__getitem__('b')))\"])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "d1_result = ts.trace.result()\n",
    "d1_stms = ts.trace.statements()\n",
    "(d1_result, d1_stms)"
   ]
  },
  {
   "source": [
    "The right-hand side of each statement is a fully resolved and type checked expressions in normal form, e.g. see the assignment to c5. Arguments to all expressions are Python values or references to variables introduced earlier.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "What can we do with such trace? We can \n",
    " * analyze it for type correctness or for privacy flows\n",
    " * optimize and rewrite it\n",
    " * capture it, ship it to another machine and re-execute with or without data. \n",
    " \n",
    "Here we just replay the trace using Pythons exec and eval (TODO: Use fully qualified names everywhere so that the below import can be dropped). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"self._fromdata({'a':Column([], id = c0), 'b':Column([], id = c1), 'c':Column([], id = c2), 'e':Column([], id = c4), id = c5})\""
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import torcharrow\n",
    "from torcharrow.dtypes import Struct, Field, int64\n",
    "\n",
    "# execute the statements\n",
    "s0 = T.Scope()\n",
    "for stm in d1_stms:\n",
    "    exec(stm)\n",
    "#eval the result\n",
    "str(eval(d1_result))"
   ]
  },
  {
   "source": [
    "We see that `d1` and `eval(d1_result)` are structurally exactly the same, including their object ids. Thus the trace preserved 100% of the original semantics. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
